{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from catboost import CatBoostClassifier, cv, Pool\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import KFold\n",
    "from paramsearch import paramsearch\n",
    "from itertools import product,chain\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "\n",
    "MSLR_PATH = '../../../MSLR-WEB10K'\n",
    "MSLR_DUMPS_PATH = '../../../mslr_dumps'\n",
    "\n",
    "params = {'depth':[3,1,2,6,4,5,7,8,9,10],\n",
    "          'iterations': [10],\n",
    "          'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3], \n",
    "          'l2_leaf_reg':[3,1,5,10,100],\n",
    "          'border_count':[32,5,10,20,50,100,200],\n",
    "          'ctr_border_count':[50,5,10,20,100,200],\n",
    "          'thread_count':4}\n",
    "\n",
    "\n",
    "# this function does 3-fold crossvalidation with catboostclassifier          \n",
    "def crossvaltest(params,train_set,train_label,cat_dims,n_splits=3):\n",
    "    kf = KFold(n_splits=n_splits,shuffle=True) \n",
    "    res = []\n",
    "    for train_index, test_index in tqdm(kf.split(train_set)):\n",
    "        train = train_set[train_index,:]\n",
    "        test = train_set[test_index,:]\n",
    "        \n",
    "        labels = train_label[train_index]\n",
    "        test_labels = train_label[test_index]\n",
    "        \n",
    "        clf = cb.CatBoostClassifier(**params)\n",
    "        clf.fit(train, np.ravel(labels), cat_features=cat_dims)\n",
    "        \n",
    "        res.append(np.mean(clf.predict(test)==np.ravel(test_labels)))\n",
    "    return np.mean(res)\n",
    "  \n",
    "# this function runs grid search on several parameters\n",
    "def catboost_param_tune(params,train_set,train_label,cat_dims=None,n_splits=3):\n",
    "    ps = paramsearch(params)\n",
    "    # search 'border_count', 'l2_leaf_reg' etc. individually \n",
    "    #   but 'iterations','learning_rate' together\n",
    "    for prms in tqdm(chain(ps.grid_search(['border_count']),\n",
    "                      ps.grid_search(['ctr_border_count']),\n",
    "                      ps.grid_search(['l2_leaf_reg']),\n",
    "                      ps.grid_search(['iterations','learning_rate']),\n",
    "                      ps.grid_search(['depth']))):\n",
    "        print(prms)\n",
    "        res = crossvaltest(prms,train_set,train_label,cat_dims,n_splits)\n",
    "        # save the crossvalidation result so that future iterations can reuse the best parameters\n",
    "        ps.register_result(res,prms)\n",
    "        print(res,prms, 'best:',ps.bestscore(),ps.bestparam())\n",
    "    return ps.bestparam()\n",
    "\n",
    "def parse_file(g):\n",
    "    features = []\n",
    "    answer = []\n",
    "\n",
    "    for line in g:\n",
    "        line_splitted = line.strip().split(' ')\n",
    "        answer.append(int(line_splitted[0]))\n",
    "\n",
    "        features_vector = []\n",
    "        for element in line_splitted[1:]:\n",
    "            element_splitted = element.split(':')\n",
    "            features_vector.append(float(element_splitted[1]))\n",
    "        features.append(features_vector)\n",
    "    return {'X': np.array(features, dtype=np.float32), 'y': np.asarray(answer, dtype=np.int8)}\n",
    "\n",
    "\n",
    "def get_mslr_data():\n",
    "    for fold in os.listdir(MSLR_PATH):\n",
    "        print(fold)\n",
    "        cur_fold = {}\n",
    "\n",
    "        with open(os.path.join(MSLR_PATH, fold, 'train.txt')) as f:\n",
    "            cur_fold['train'] = parse_file(f)\n",
    "        print('train')\n",
    "        with open(os.path.join(MSLR_PATH, fold, 'test.txt')) as f:\n",
    "            cur_fold['test'] = parse_file(f)\n",
    "        print('test')\n",
    "        with open(os.path.join(MSLR_PATH, fold, 'vali.txt')) as f:\n",
    "            cur_fold['vali'] = parse_file(f)\n",
    "        print('vali')\n",
    "        yield fold, cur_fold\n",
    "\n",
    "\n",
    "def init_folds():\n",
    "    for fold_name, data in get_mslr_data():\n",
    "        with open(os.path.join(MSLR_DUMPS_PATH, fold_name), 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "            \n",
    "\n",
    "def get_features_mapping(amount):\n",
    "    output = []\n",
    "    i = 1\n",
    "    while len(output) < amount:\n",
    "        if i % 5 != 0 and i % 5 != 4:\n",
    "            output.append(i)\n",
    "        i += 1\n",
    "    return output\n",
    "\n",
    "def load_folds():\n",
    "    for fold_name in os.listdir(MSLR_DUMPS_PATH):\n",
    "        with open(os.path.join(MSLR_DUMPS_PATH, fold_name), 'rb') as f:\n",
    "            yield fold_name, pickle.load(f)\n",
    "\n",
    "\n",
    "def filter_features(np_array):\n",
    "#     exclude = [0] + list(range(101, 126)) + [128] + list(range(131, 137))\n",
    "#     return np.delete(np_array, exclude, axis=1)\n",
    "    include = get_features_mapping(19 * 3)\n",
    "    include.remove(16)\n",
    "    include.remove(17)\n",
    "    include.remove(18)\n",
    "    return MinMaxScaler().fit_transform(np_array[:, include])\n",
    "\n",
    "def modify_answers(np_array):\n",
    "    np_array[np_array == 1] = 0\n",
    "    np_array[np_array == 2] = 1\n",
    "\n",
    "    np_array[np_array == 3] = 1\n",
    "    np_array[np_array == 4] = 1\n",
    "\n",
    "    return np_array\n",
    "\n",
    "def oversample(X, y):\n",
    "    repeat_factor = int(len(y[y==0]) / len(y[y==1]))\n",
    "    new_X = np.concatenate((X[y==0], X[y==1].repeat(repeat_factor, axis=0)), axis=0)\n",
    "    new_y = np.concatenate((y[y==0], y[y==1].repeat(repeat_factor, axis=0)), axis=0)\n",
    "    return new_X, new_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_model():\n",
    "    fold_name, fold = next(load_folds())\n",
    "    train = fold['train']\n",
    "    eval_set = fold['vali']\n",
    "    train['X'] = filter_features(train['X'])\n",
    "    eval_set['X'] = filter_features(eval_set['X'])\n",
    "    train['y'] = modify_answers(train['y'])\n",
    "    eval_set['y'] = modify_answers(eval_set['y'])\n",
    "    \n",
    "    X, y = train['X'], train['y']\n",
    "    bestparams = catboost_param_tune(params, X, y, [])\n",
    "    return bestparams\n",
    "    \n",
    "\n",
    "def train_model():\n",
    "    model = cb.CatBoostClassifier(depth=10, iterations=5000, learning_rate=0.005, thread_count=4,)\n",
    "                                  #save_snapshot=True)\n",
    "\n",
    "    baseline = None\n",
    "    for fold_name, fold in load_folds():\n",
    "        print(fold_name)\n",
    "        train = fold['train']\n",
    "        eval_set = fold['vali']\n",
    "        train['X'] = filter_features(train['X'])\n",
    "        eval_set['X'] = filter_features(eval_set['X'])\n",
    "        train['y'] = modify_answers(train['y'])\n",
    "        eval_set['y'] = modify_answers(eval_set['y'])\n",
    "        \n",
    "        X, y = oversample(train['X'], train['y'])\n",
    "        pool = Pool(X, y)\n",
    "        eval_pool = Pool(eval_set['X'], eval_set['y'])\n",
    "#         if baseline is not None:\n",
    "#             pool.set_baseline(baseline)\n",
    "#             eval_pool.set_baseline(eval_baseline)\n",
    "        print('Started training')\n",
    "\n",
    "        model.fit(\n",
    "            X, y,\n",
    "            eval_set=(eval_set['X'], eval_set['y']),\n",
    "            verbose=True,\n",
    "            plot=True,\n",
    "        )\n",
    "#         baseline = model.predict(pool, prediction_type='RawFormulaVal')\n",
    "#         eval_baseline = model.predict(eval_pool, prediction_type='RawFormulaVal')\n",
    "        break\n",
    "        \n",
    "    return model\n",
    "\n",
    "# bestparams = choose_best_model()\n",
    "# trained_model = train_model()\n",
    "trained_model = cb.CatBoostClassifier().load_model('catboost_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_name, fold = next(load_folds())\n",
    "test = fold['test']\n",
    "test['X'] = filter_features(test['X'])\n",
    "test['y'] = modify_answers(test['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828651720168\n"
     ]
    }
   ],
   "source": [
    "print(trained_model.score(test['X'], test['y']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(trained_model, test['X'], test['y'], scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[199042   4968]\n",
      " [ 36555   1766]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "true_values = test['y']\n",
    "predicted_values = trained_model.predict(test['X'])\n",
    "print(confusion_matrix(true_values, predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.save_model()\n",
    "import pickle\n",
    "with open('catboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(trained_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatboostError",
     "evalue": "catboost/libs/algo/calc_fstr.cpp:197: train and test datasets should have the same feature count",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatboostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cb009c63dda5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m trained_model = CatBoostClassifier(iterations=50, loss_function='Logloss', depth=10,\n\u001b[1;32m      2\u001b[0m                                learning_rate=0.1, class_weights=[1, 4], border=0.7)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mget_feature_importance\u001b[0;34m(self, X, y, cat_features, weight, baseline, thread_count, fstr_type)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatboostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X is empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mfstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_fstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfstr_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfstr_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FeatureImportance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoostBase._calc_fstr (/home/donskov/.ya/build/build_root/miha/000350/catboost/python-package/catboost/_catboost.pyx.cpp:16835)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._calc_fstr (/home/donskov/.ya/build/build_root/miha/000350/catboost/python-package/catboost/_catboost.pyx.cpp:12482)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._calc_fstr (/home/donskov/.ya/build/build_root/miha/000350/catboost/python-package/catboost/_catboost.pyx.cpp:12341)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatboostError\u001b[0m: catboost/libs/algo/calc_fstr.cpp:197: train and test datasets should have the same feature count"
     ]
    }
   ],
   "source": [
    "trained_model = CatBoostClassifier(iterations=50, loss_function='Logloss', depth=10,\n",
    "                               learning_rate=0.1, class_weights=[1, 4], border=0.7)\n",
    "result = trained_model.get_feature_importance(X=test['X'], y=test['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204010, 137)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(191605, 137)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = test['y']\n",
    "X[y==0].shape)\n",
    "X[y==1].repeat(5, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395615, 137)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((X[y==0], X[y==1].repeat(5, axis=0)), axis=0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395615,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((y[y==0], y[y==1].repeat(5, axis=0)), axis=0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  7.00000000e+00,   2.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  7.00000000e+00,   3.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  7.00000000e+00,   3.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  2.99770000e+04,   1.00000000e+00,   1.00000000e+00, ...,\n",
       "           0.00000000e+00,   1.96082000e+05,   5.20749321e+01],\n",
       "        [  2.99770000e+04,   1.00000000e+00,   1.00000000e+00, ...,\n",
       "           0.00000000e+00,   1.96082000e+05,   5.20749321e+01],\n",
       "        [  2.99770000e+04,   1.00000000e+00,   1.00000000e+00, ...,\n",
       "           0.00000000e+00,   1.96082000e+05,   5.20749321e+01]], dtype=float32),\n",
       " array([0, 0, 0, ..., 1, 1, 1], dtype=int8))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4\n",
      "train\n",
      "test\n",
      "vali\n",
      "Fold1\n",
      "train\n",
      "test\n",
      "vali\n",
      "Fold2\n",
      "train\n",
      "test\n",
      "vali\n",
      "Fold5\n",
      "train\n",
      "test\n",
      "vali\n",
      "Fold3\n",
      "train\n",
      "test\n",
      "vali\n"
     ]
    }
   ],
   "source": [
    "init_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = trained_model.get_feature_importance(test['X'], test['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "include = get_features_mapping(19 * 3)\n",
    "include.remove(16)\n",
    "include.remove(17)\n",
    "include.remove(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9998886275626093\n",
      "2 0.2590262886852381\n",
      "3 1.5815194319609835\n",
      "6 1.7245759343857268\n",
      "7 0.3081338221392781\n",
      "8 2.1757460401305195\n",
      "11 9.037517992333369\n",
      "12 2.497815930751388\n",
      "13 5.7415687907977535\n",
      "21 0.3065074590379698\n",
      "22 0.1335382409910288\n",
      "23 0.7733841812830988\n",
      "26 3.5882196952950736\n",
      "27 0.12349250443778978\n",
      "28 0.17906268494424832\n",
      "31 3.366307156509057\n",
      "32 0.047821198663354346\n",
      "33 0.43155616655759577\n",
      "36 5.1465092875457685\n",
      "37 0.10777963572620804\n",
      "38 1.5148102595132078\n",
      "41 5.532787082067535\n",
      "42 0.10541833685374692\n",
      "43 1.5713743425168287\n",
      "46 0.46643049391922875\n",
      "47 0.673655579786749\n",
      "48 4.903354293687211\n",
      "51 5.187003757001774\n",
      "52 0.09072530909912854\n",
      "53 1.8052731779311808\n",
      "56 3.374532806191194\n",
      "57 0.271573130609776\n",
      "58 3.0502204849715517\n",
      "61 3.883619285448456\n",
      "62 0.18256110306662035\n",
      "63 3.3311673924852068\n",
      "66 3.462068806137715\n",
      "67 0.19211426733561593\n",
      "68 1.436162263089875\n",
      "71 0.0011436471150118332\n",
      "72 0.8581667941147135\n",
      "73 1.7298842137320798\n",
      "76 0.005556345709979016\n",
      "77 0.20749461860060692\n",
      "78 2.3253795105379007\n",
      "81 3.4276699247144493\n",
      "82 0.40345532331821227\n",
      "83 1.489609916318278\n",
      "86 0.01559623679784657\n",
      "87 0.49524372074153483\n",
      "88 2.594090626069643\n",
      "91 4.057014951875165\n",
      "92 0.20809118873020743\n",
      "93 2.6167797401737336\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(include, feature_importance):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
